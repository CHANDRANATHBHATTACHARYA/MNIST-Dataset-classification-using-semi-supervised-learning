{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Klktno2bFjLI",
        "outputId": "41905c6f-ee3d-4209-be08-8e443d74a744"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing k-means clustering...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected training set based on clustering.\n",
            "Epoch 1/30\n",
            "53/53 - 1s - loss: 1.5904 - accuracy: 0.4496 - 1s/epoch - 25ms/step\n",
            "Epoch 2/30\n",
            "53/53 - 0s - loss: 1.1024 - accuracy: 0.6421 - 344ms/epoch - 6ms/step\n",
            "Epoch 3/30\n",
            "53/53 - 0s - loss: 0.9497 - accuracy: 0.6888 - 348ms/epoch - 7ms/step\n",
            "Epoch 4/30\n",
            "53/53 - 0s - loss: 0.7856 - accuracy: 0.7320 - 318ms/epoch - 6ms/step\n",
            "Epoch 5/30\n",
            "53/53 - 0s - loss: 0.7218 - accuracy: 0.7572 - 183ms/epoch - 3ms/step\n",
            "Epoch 6/30\n",
            "53/53 - 0s - loss: 0.8472 - accuracy: 0.7302 - 188ms/epoch - 4ms/step\n",
            "Epoch 7/30\n",
            "53/53 - 0s - loss: 0.6075 - accuracy: 0.7944 - 186ms/epoch - 4ms/step\n",
            "Epoch 8/30\n",
            "53/53 - 0s - loss: 0.5328 - accuracy: 0.8213 - 215ms/epoch - 4ms/step\n",
            "Epoch 9/30\n",
            "53/53 - 0s - loss: 0.5234 - accuracy: 0.8177 - 189ms/epoch - 4ms/step\n",
            "Epoch 10/30\n",
            "53/53 - 0s - loss: 0.4652 - accuracy: 0.8387 - 203ms/epoch - 4ms/step\n",
            "Epoch 11/30\n",
            "53/53 - 0s - loss: 0.4319 - accuracy: 0.8519 - 178ms/epoch - 3ms/step\n",
            "Epoch 12/30\n",
            "53/53 - 0s - loss: 0.4100 - accuracy: 0.8585 - 198ms/epoch - 4ms/step\n",
            "Epoch 13/30\n",
            "53/53 - 0s - loss: 0.3771 - accuracy: 0.8759 - 198ms/epoch - 4ms/step\n",
            "Epoch 14/30\n",
            "53/53 - 0s - loss: 0.3304 - accuracy: 0.8951 - 182ms/epoch - 3ms/step\n",
            "Epoch 15/30\n",
            "53/53 - 0s - loss: 0.2991 - accuracy: 0.9011 - 198ms/epoch - 4ms/step\n",
            "Epoch 16/30\n",
            "53/53 - 0s - loss: 0.2866 - accuracy: 0.9107 - 173ms/epoch - 3ms/step\n",
            "Epoch 17/30\n",
            "53/53 - 0s - loss: 0.2886 - accuracy: 0.9065 - 182ms/epoch - 3ms/step\n",
            "Epoch 18/30\n",
            "53/53 - 0s - loss: 0.2889 - accuracy: 0.9053 - 190ms/epoch - 4ms/step\n",
            "Epoch 19/30\n",
            "53/53 - 0s - loss: 0.2301 - accuracy: 0.9293 - 190ms/epoch - 4ms/step\n",
            "Epoch 20/30\n",
            "53/53 - 0s - loss: 0.2375 - accuracy: 0.9281 - 179ms/epoch - 3ms/step\n",
            "Epoch 21/30\n",
            "53/53 - 0s - loss: 0.2746 - accuracy: 0.9197 - 176ms/epoch - 3ms/step\n",
            "Epoch 22/30\n",
            "53/53 - 0s - loss: 0.2392 - accuracy: 0.9275 - 357ms/epoch - 7ms/step\n",
            "Epoch 23/30\n",
            "53/53 - 0s - loss: 0.2033 - accuracy: 0.9442 - 237ms/epoch - 4ms/step\n",
            "Epoch 24/30\n",
            "53/53 - 0s - loss: 0.2629 - accuracy: 0.9161 - 174ms/epoch - 3ms/step\n",
            "Epoch 25/30\n",
            "53/53 - 0s - loss: 0.2106 - accuracy: 0.9382 - 217ms/epoch - 4ms/step\n",
            "Epoch 26/30\n",
            "53/53 - 0s - loss: 0.1931 - accuracy: 0.9424 - 379ms/epoch - 7ms/step\n",
            "Epoch 27/30\n",
            "53/53 - 0s - loss: 0.1735 - accuracy: 0.9520 - 192ms/epoch - 4ms/step\n",
            "Epoch 28/30\n",
            "53/53 - 0s - loss: 0.1459 - accuracy: 0.9574 - 182ms/epoch - 3ms/step\n",
            "Epoch 29/30\n",
            "53/53 - 0s - loss: 0.1981 - accuracy: 0.9341 - 188ms/epoch - 4ms/step\n",
            "Epoch 30/30\n",
            "53/53 - 0s - loss: 0.1700 - accuracy: 0.9490 - 377ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 4.6336 - accuracy: 0.4573 - 205ms/epoch - 6ms/step\n",
            "Test accuracy: 45.73%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "import tensorflow as tf\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import pairwise_distances_argmin_min\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.manifold import TSNE\n",
        "import pandas as pd\n",
        "\n",
        "def load_overhead_mnist():\n",
        "\n",
        "    # Read CSV files\n",
        "    train_df = pd.read_csv('train.csv')\n",
        "    test_df = pd.read_csv('test.csv')\n",
        "\n",
        "    # Extract labels\n",
        "    train_labels = train_df['label'].values\n",
        "    test_labels = test_df['label'].values\n",
        "\n",
        "    # Drop label column to isolate pixel data\n",
        "    train_df.drop(columns=['label'], inplace=True)\n",
        "    test_df.drop(columns=['label'], inplace=True)\n",
        "\n",
        "    # Convert dataframe to numpy array and reshape to image format\n",
        "    train_images = train_df.values.reshape(-1, 28, 28)\n",
        "    test_images = test_df.values.reshape(-1, 28, 28)\n",
        "\n",
        "    # Normalize pixel values to be between 0 and 1\n",
        "    train_images = train_images / 255.0\n",
        "    test_images = test_images / 255.0\n",
        "\n",
        "    return (train_images, train_labels), (test_images, test_labels)\n",
        "\n",
        "def perform_kmeans_and_select_samples(train_images, train_labels, num_clusters=150):\n",
        "    print(\"Performing k-means clustering...\")\n",
        "    n_samples, nx, ny = train_images.shape\n",
        "    train_images_reshaped = train_images.reshape((n_samples, nx*ny))\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0)\n",
        "    kmeans.fit(train_images_reshaped)\n",
        "    centroids = kmeans.cluster_centers_\n",
        "\n",
        "    closest, _ = pairwise_distances_argmin_min(centroids, train_images_reshaped)\n",
        "    cluster_labels = kmeans.labels_\n",
        "    training_indices = []\n",
        "\n",
        "    for i in range(num_clusters):\n",
        "        cluster_indices = np.where(cluster_labels == i)[0]\n",
        "        distances = np.linalg.norm(train_images_reshaped[cluster_indices] - centroids[i], axis=1)\n",
        "        num_select = max(int(0.2 * len(cluster_indices)), 1)\n",
        "        nearest_indices = np.argsort(distances)[:num_select]\n",
        "        training_indices.extend(cluster_indices[nearest_indices])\n",
        "\n",
        "    selected_train_images = train_images_reshaped[training_indices]\n",
        "    selected_train_labels = train_labels[training_indices]\n",
        "    print(\"Selected training set based on clustering.\")\n",
        "\n",
        "    return selected_train_images, selected_train_labels\n",
        "\n",
        "def build_neural_network(input_shape):\n",
        "    model = Sequential([\n",
        "        Flatten(input_shape=input_shape),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    (train_images, train_labels), (test_images, test_labels) = load_overhead_mnist()\n",
        "\n",
        "    # Check for NaN values in the datasets\n",
        "    if np.isnan(train_images).any():\n",
        "        print(\"NaN values found in train_images. Filling with the mean of each column.\")\n",
        "        # Fill NaNs with the mean of the column\n",
        "        col_mean = np.nanmean(train_images, axis=0)\n",
        "        inds = np.where(np.isnan(train_images))\n",
        "        train_images[inds] = np.take(col_mean, inds[1])\n",
        "\n",
        "    selected_train_images, selected_train_labels = perform_kmeans_and_select_samples(train_images, train_labels)\n",
        "\n",
        "    # Flatten the images for the neural network\n",
        "    n_samples, nx, ny = train_images.shape\n",
        "    selected_train_images = selected_train_images.reshape((selected_train_images.shape[0], nx*ny))\n",
        "\n",
        "    # Scaling the data\n",
        "    scaler = StandardScaler()\n",
        "    selected_train_images = scaler.fit_transform(selected_train_images)\n",
        "    test_images_reshaped = test_images.reshape((test_images.shape[0], nx*ny))\n",
        "    test_images_reshaped = scaler.transform(test_images_reshaped)\n",
        "\n",
        "    model = build_neural_network((nx*ny,))\n",
        "    model.fit(selected_train_images, selected_train_labels, epochs=30, verbose=2)\n",
        "\n",
        "    # Evaluate the model on the test data\n",
        "    test_loss, test_accuracy = model.evaluate(test_images_reshaped, test_labels, verbose=2)\n",
        "    print(f\"Test accuracy: {test_accuracy*100:.2f}%\")\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The last tms/step signifies that it took t ms to complete this step. The loss function quantifies how accurately the model's predictions match the actual labels, a lower value signifying a better match. Accuracy gives the fraction of times the model correctly predicted the labeled value, denominator being the total values"
      ],
      "metadata": {
        "id": "4VBQzQ1Va8u7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Epoch m/n signifies that out of m total epochs, n have been traversed. An epoch is a pass through the entire dataset\n",
        "## 53/53 signifies 53 batches out of 53 batches have been processed. The whole dataset was divided into 53 batches\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zdw8AnprZe_E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oM3KQILIFjLK",
        "outputId": "bf4be85f-3c9b-45be-aa9c-1465b29bae8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in train.csv: Index(['label', 'pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5', 'pixel6',\n",
            "       'pixel7', 'pixel8', 'pixel9',\n",
            "       ...\n",
            "       'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779', 'pixel780',\n",
            "       'pixel781', 'pixel782', 'pixel783', 'pixel784'],\n",
            "      dtype='object', length=785)\n",
            "Columns in test.csv: Index(['label', 'pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5', 'pixel6',\n",
            "       'pixel7', 'pixel8', 'pixel9',\n",
            "       ...\n",
            "       'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779', 'pixel780',\n",
            "       'pixel781', 'pixel782', 'pixel783', 'pixel784'],\n",
            "      dtype='object', length=785)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "# Load the train.csv to check the column names\n",
        "train_df = pd.read_csv('train.csv')\n",
        "print(\"Columns in train.csv:\", train_df.columns)\n",
        "\n",
        "# Load the test.csv to check the column names\n",
        "test_df = pd.read_csv('test.csv')\n",
        "print(\"Columns in test.csv:\", test_df.columns)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}